{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hdtruong802/Pytorch-Assignments/blob/main/%5BNLP%5DPart2_Build_GPTModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dự án thực hành\n",
        "```\n",
        "ProtonX - Pytorch Class\n",
        "```\n",
        "\n",
        "### Hướng dẫn làm bài\n",
        "- Trong bài tập này bạn sẽ sử dụng Python 3.\n",
        "- Sau khi bạn viết Code của mình xong, hãy chạy dòng Code đó để xem kết quả bên dưới.\n",
        "\n",
        "### [Quan trọng] Chú ý\n",
        "- **Không sử dụng hàm `input()` tại bất kỳ dòng lệnh nào**\n",
        "- **Không thay đổi dòng code return của hàm**\n",
        "\n",
        "Các bạn sẽ thực hiện `code` trong các phần hiển thị `#TODO: Lập trình tại đây` và thay thế các vị trí `None`. Có những câu hỏi chỉ cần trả về đáp án.\n",
        "\n",
        "Sau khi viết xong Code của bạn, bạn hãy ấn \"SHIFT\"+\"ENTER\" để thực hiện chạy lệnh của Cell đó.\n",
        "\n",
        "---\n",
        "Điểm số:\n",
        "* 10 điểm / Câu\n",
        "\n",
        "Tiêu chí chấm điểm:\n",
        "* Các bài tập sẽ được chấm dựa trên các Test-case.\n",
        "* Các bạn không khởi tạo lại giá trị đầu vào bên trong hàm. Có thể khởi tạo các giá trị này ngoài hàm nhằm mục đích kiểm thử."
      ],
      "metadata": {
        "id": "b6juhql4uLKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phần 1: Tách token"
      ],
      "metadata": {
        "id": "Wxks2Uctsw9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cài đặt bộ tokenizer bên thứ 3**\n",
        "\n",
        "Xem thêm về các bộ tách từ xây dựng bằng [Spacy](https://protonx.io/courses/6523788337e7f90012890145/topics/6571b351e5bfd8001a8f0d50)."
      ],
      "metadata": {
        "id": "2KFT6U5jgBND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "fm_i21VYKNbj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYDTzb8scUSW",
        "outputId": "1f458d11-e5ad-40c9-ac38-e91d1bc5ec1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyvi\n",
            "  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n",
            "Collecting sklearn-crfsuite (from pyvi)\n",
            "  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.3.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.2)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pyvi\n",
        "from spacy.lang.vi import Vietnamese"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thử tokenizer này"
      ],
      "metadata": {
        "id": "HJpTgW0xfkZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = Vietnamese()\n",
        "tokens = nlp('Lớp học Pytorch là lớp học rất hay ho')"
      ],
      "metadata": {
        "id": "2IBG31xffkGp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Zbw7oYfw74",
        "outputId": "0b40774f-3820-47a7-dda1-b5c7e04943fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lớp học Pytorch là lớp học rất hay ho"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lặp qua các đơn vị lưu trữ trong Vocab dưới dạng từ vựng (Lexeme). Một từ vựng có các thuộc tính sau:"
      ],
      "metadata": {
        "id": "BPFDAXXngJ6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in tokens:\n",
        "    lexeme = tokens.vocab[word.text]\n",
        "    print(lexeme.text, lexeme.orth, lexeme.shape_, lexeme.prefix_, lexeme.suffix_,\n",
        "            lexeme.is_alpha, lexeme.is_digit, lexeme.is_title, lexeme.lang_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWw1WMRzgJSI",
        "outputId": "a85d8926-a88d-41af-9114-c6c06ed5787d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lớp học 9560392879819997953 Xxx xxx L học False False False vi\n",
            "Pytorch 16295890598922194816 Xxxxx P rch True False True vi\n",
            "là 12844001651356581174 xx l là True False False vi\n",
            "lớp học 16939850666758009144 xxx xxx l học False False False vi\n",
            "rất 1932685823275808203 xxx r rất True False False vi\n",
            "hay ho 3393752619603724165 xxx xx h  ho False False False vi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Văn bản: Văn bản gốc của từ vựng.\n",
        "\n",
        "- Orth: Giá trị băm của từ vựng.\n",
        "\n",
        "- Shape: Hình dạng từ ngữ trừu tượng của từ vựng.\n",
        "\n",
        "- Prefix: Theo mặc định, là chữ cái đầu tiên của chuỗi từ.\n",
        "\n",
        "- Suffix: Theo mặc định, là ba chữ cái cuối cùng của chuỗi từ.\n",
        "\n",
        "- is alpha: Liệu từ vựng có bao gồm các ký tự chữ cái không?\n",
        "\n",
        "- is digit: Liệu từ vựng có bao gồm các chữ số không?"
      ],
      "metadata": {
        "id": "39eBBiwsgVu-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phân tích: Có rất nhiều câu ngắn trong dữ liệu vì thế bạn hãy lọc những câu có chiều dài ngắn hơn 10 từ và tiến hành tách token"
      ],
      "metadata": {
        "id": "qy02qpKcl4cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwPc0vzEgYsP",
        "outputId": "f22c073e-ab19-49a7-8b73-a15b828d019d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile wiki.txt\n",
        "Những gì bạn sẽ học được từ lớp học này\n",
        "\n",
        "Hiểu cách các mô hình học sâu hoạt động\n",
        "\n",
        "Triển khai các model tiên tiến nhất với Pytorch bao gồm thị giác máy tính và xử lý ngôn ngữ tự nhiên\n",
        "\n",
        "Cách làm việc với nhiều loại dữ liệu khác nhau để xây dựng model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfVljJlbf_ip",
        "outputId": "4b23d479-7428-490d-d7d5-d1222433eab1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing wiki.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import io\n",
        "\n",
        "def count_tokens_in_file(filepath, min_length):\n",
        "    \"\"\"\n",
        "    Hàm này đọc một tệp tin văn bản và đếm số lượng xuất hiện của từng token.\n",
        "    Chỉ xử lý các câu có chiều dài lớn hơn hoặc bằng min_length.\n",
        "\n",
        "    Args:\n",
        "    filepath: Đường dẫn đến tệp tin văn bản.\n",
        "    min_length: Độ dài tối thiểu của câu để được xử lý.\n",
        "\n",
        "    Returns:\n",
        "    Counter object với số lượng xuất hiện của mỗi token.\n",
        "    \"\"\"\n",
        "\n",
        "    # Bộ đếm token và số lượng xuất hiện\n",
        "    counter = Counter()\n",
        "\n",
        "    # Mở File\n",
        "    with io.open(filepath, encoding=\"utf8\") as f:\n",
        "        for string_ in f:\n",
        "            # Chỉ làm việc với những câu có chiều dài lớn hơn hoặc bằng min_length\n",
        "            # Tiến hành tách token\n",
        "            doc = nlp(string_)\n",
        "            # Update counter với bộ đếm\n",
        "            counter.update([token.text for token in doc])\n",
        "    return counter\n",
        "\n",
        "# Sử dụng hàm\n",
        "filepath = '/content/wiki.txt'\n",
        "min_length = 10\n",
        "counter = count_tokens_in_file(filepath, min_length)"
      ],
      "metadata": {
        "id": "FfK5ZAycqUr1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Từ bộ đếm này, xây dựng từ điển bằng Pytorch\n",
        "\n"
      ],
      "metadata": {
        "id": "Nj9dJH1mmd0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Token không có\n",
        "unk_token = '<unk>'\n",
        "# Token để padding\n",
        "pad_token = '<pad>'\n",
        "# Token bắt đầu câu\n",
        "bos_token = '<bos>'\n",
        "# Token kết thúc câu\n",
        "eos_token = '<eos>'\n",
        "\n",
        "from torchtext.vocab import vocab\n",
        "# TODO 5: Xây dựng Vocab bằng Pytorch\n",
        "torchVocab = vocab(counter, specials=[unk_token, pad_token , bos_token, eos_token])"
      ],
      "metadata": {
        "id": "yuV6vdb6mc9Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code"
      ],
      "metadata": {
        "id": "4-KT04cwm4TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_initialization():\n",
        "    try:\n",
        "        assert unk_token in torchVocab.get_stoi()\n",
        "        assert pad_token in torchVocab.get_stoi()\n",
        "        assert bos_token in torchVocab.get_stoi()\n",
        "        assert eos_token in torchVocab.get_stoi()\n",
        "        print(\"Test Initialization: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Initialization: Failed\")\n",
        "\n",
        "def test_special_tokens():\n",
        "    try:\n",
        "        for token in [unk_token, pad_token, bos_token, eos_token]:\n",
        "            assert token in torchVocab.get_stoi()\n",
        "        print(\"Test Special Tokens: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Special Tokens: Failed\")\n",
        "\n",
        "def test_token_to_index():\n",
        "    try:\n",
        "        known_token = list(counter.keys())[0]\n",
        "        assert torchVocab[known_token] == torchVocab.get_stoi()[known_token]\n",
        "        assert torchVocab['<unk>'] == torchVocab.get_stoi()[str(unk_token)]\n",
        "        print(\"Test Token to Index Conversion: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Token to Index Conversion: Failed\")\n",
        "\n",
        "def test_index_to_token():\n",
        "    try:\n",
        "        known_index = torchVocab.get_stoi()[list(counter.keys())[0]]\n",
        "        assert torchVocab.get_itos()[known_index] == list(counter.keys())[0]\n",
        "        print(\"Test Index to Token Conversion: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Index to Token Conversion: Failed\")\n",
        "\n",
        "def test_vocabulary_size():\n",
        "    try:\n",
        "        expected_size = len(counter) + 4  # 4 for the special tokens\n",
        "        assert len(torchVocab) == expected_size\n",
        "        print(\"Test Vocabulary Size: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Vocabulary Size: Failed\")\n",
        "\n",
        "def test_unknown_token_handling():\n",
        "    try:\n",
        "        assert torchVocab['<unk>'] == torchVocab.get_stoi()[unk_token]\n",
        "        print(\"Test Handling of Unknown Tokens: Passed\")\n",
        "    except AssertionError:\n",
        "        print(\"Test Handling of Unknown Tokens: Failed\")\n",
        "\n",
        "\n",
        "test_initialization()\n",
        "test_special_tokens()\n",
        "test_token_to_index()\n",
        "test_index_to_token()\n",
        "test_vocabulary_size()\n",
        "test_unknown_token_handling()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9ehpKmSm2gl",
        "outputId": "3eeda61f-9a76-4493-f3ef-fe632247cc54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Initialization: Passed\n",
            "Test Special Tokens: Passed\n",
            "Test Token to Index Conversion: Passed\n",
            "Test Index to Token Conversion: Passed\n",
            "Test Vocabulary Size: Passed\n",
            "Test Handling of Unknown Tokens: Passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kết quả mong đợi:**\n",
        "\n",
        "```\n",
        "Test Initialization: Passed\n",
        "Test Special Tokens: Passed\n",
        "Test Token to Index Conversion: Passed\n",
        "Test Index to Token Conversion: Passed\n",
        "Test Vocabulary Size: Passed\n",
        "Test Handling of Unknown Tokens: Passed\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "mLmVK5D1ns7b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 4\n",
        "PAD_IDX = torchVocab['<pad>']\n",
        "BOS_IDX = torchVocab['<bos>']\n",
        "EOS_IDX = torchVocab['<eos>']"
      ],
      "metadata": {
        "id": "uR58dHjOnUDG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lập trình hàm cắt một chuỗi thành nhiều chuỗi nhỏ"
      ],
      "metadata": {
        "id": "DTjde8S2oCXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hàm `trim_sequence_to_parts` có chức năng chia một chuỗi (hoặc một dãy các phần tử) thành nhiều phần nhỏ với độ dài xác định. Dưới đây là mô tả chi tiết về các đối số đầu vào và giá trị trả về của hàm này:\n",
        "\n",
        "**Đối số:**\n",
        "1. `sequence`: Đây là chuỗi hoặc dãy các phần tử cần được chia nhỏ. Đối số này có thể là một chuỗi các ký tự, một danh sách, hoặc bất kỳ đối tượng nào khác có thể được lặp qua (iterable).\n",
        "2. `part_length`: Đây là độ dài của từng phần sau khi chia. Đối số này phải là một số nguyên, chỉ ra số lượng phần tử tối đa trong mỗi phần nhỏ sau khi chia.\n",
        "\n",
        "**Chức năng của Hàm:**\n",
        "- Hàm `trim_sequence_to_parts` lặp qua `sequence` và chia nó thành các phần nhỏ, mỗi phần có độ dài không vượt quá `part_length`.\n",
        "- Việc chia này được thực hiện bằng cách sử dụng list comprehension, một cấu trúc ngắn gọn trong Python để tạo ra các danh sách mới.\n",
        "\n",
        "**Giá trị trả về:**\n",
        "- Hàm trả về một danh sách mới, trong đó mỗi phần tử là một phần của `sequence` với độ dài không vượt quá `part_length`.\n",
        "- Nếu `sequence` không thể chia đều cho `part_length`, phần cuối cùng của danh sách trả về có thể sẽ ngắn hơn.\n",
        "\n",
        "**Ví dụ:**\n",
        "Nếu bạn gọi `trim_sequence_to_parts([1, 2, 3, 4, 5, 6, 7], 3)`, hàm sẽ trả về `[[1, 2, 3], [4, 5, 6], [7]]`. Trong ví dụ này, chuỗi `[1, 2, 3, 4, 5, 6, 7]` được chia thành các phần, mỗi phần có 3 phần tử, trừ phần cuối cùng chỉ có 1 phần tử."
      ],
      "metadata": {
        "id": "T6hPxrhuoZ47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 30\n",
        "def trim_sequence_to_parts(sequence, part_length):\n",
        "    # TODO 5: Lập trình tại đây\n",
        "    return [sequence[i:i + part_length] for i in range(0, len(sequence), part_length)]"
      ],
      "metadata": {
        "id": "XCSRbTi3oE0T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lập trình hàm xử lý dữ liệu\n",
        "\n",
        "Hàm `data_process` là một hàm dùng để xử lý dữ liệu văn bản từ một tệp tin và chuyển đổi chúng thành dạng tensor sử dụng một từ điển (vocab). Dưới đây là mô tả chi tiết về các đối số và giá trị trả về của hàm này:\n",
        "\n",
        "**Đối số:**\n",
        "1. `filepath`: Đường dẫn đến tệp tin chứa dữ liệu văn bản cần xử lý. Đây là một chuỗi ký tự (string) chỉ ra vị trí của tệp tin trong hệ thống tập tin.\n",
        "2. `vocab`: Một từ điển hoặc cấu trúc dữ liệu tương tự, dùng để chuyển đổi từ các token văn bản sang số nguyên (index). Mỗi token trong văn bản sẽ được tìm kiếm trong `vocab` để lấy chỉ số tương ứng.\n",
        "3. `min_length`: Độ dài tối thiểu của một chuỗi ký tự (câu) để nó được xem xét và xử lý. Nếu một chuỗi ngắn hơn `min_length`, nó sẽ bị bỏ qua.\n",
        "4. `max_length`: Độ dài tối đa cho phép của một chuỗi tensor sau khi được chia nhỏ bằng hàm `trim_sequence_to_parts`.\n",
        "\n",
        "**Chức năng của Hàm:**\n",
        "- Hàm mở tệp tin văn bản tại `filepath` sử dụng mã hóa UTF-8.\n",
        "- Đọc từng dòng trong tệp tin. Mỗi dòng được coi như một chuỗi ký tự (`string_`).\n",
        "- Nếu độ dài của `string_` (tính theo số lượng từ) lớn hơn hoặc bằng `min_length`, chuỗi sẽ được xử lý tiếp:\n",
        "    - Sử dụng một hàm nlp như trên để xử lý chuỗi ký tự này, tạo ra một đối tượng (có thể là một danh sách các token).\n",
        "    - Mỗi token trong đối tượng này được chuyển đổi thành số nguyên (index) sử dụng `vocab`. Kết quả là một tensor PyTorch (`vi_tensor_`).\n",
        "    - Tensor này sau đó được chia thành nhiều phần nhỏ hơn với độ dài tối đa là `max_length` sử dụng hàm `trim_sequence_to_parts`.\n",
        "    - Mỗi phần nhỏ này được thêm vào danh sách `data`.\n",
        "\n",
        "**Giá trị trả về:**\n",
        "- Hàm trả về `data`, là một danh sách các phần tensor. Mỗi phần tensor đại diện cho một phần của dữ liệu văn bản, đã được chuyển đổi thành dạng số nguyên và chia theo độ dài tối đa xác định.\n",
        "\n"
      ],
      "metadata": {
        "id": "gTX_YN5kovww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "\n",
        "def data_process(filepath, vocab, min_length, max_length):\n",
        "    data = []\n",
        "    # TODO 6: Lập trình tại đây\n",
        "    with io.open(filepath, encoding=\"utf8\") as f:\n",
        "        for string_ in f:\n",
        "            if len(string_.split()) >= min_length:\n",
        "                doc = nlp(string_)\n",
        "                vi_tensor_ = torch.tensor([vocab[str(token)] for token in doc], dtype=torch.long)\n",
        "                parts = trim_sequence_to_parts(vi_tensor_, max_length)\n",
        "                for part in parts:\n",
        "                    data.append(part)\n",
        "    return data"
      ],
      "metadata": {
        "id": "qWrE1bt0n6NJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_process(filepath, torchVocab, 10, 30)"
      ],
      "metadata": {
        "id": "lI-oQfeWPUHT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code"
      ],
      "metadata": {
        "id": "CVvSEQ21pLLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.txt\n",
        "Những gì bạn sẽ học được từ lớp học này\n",
        "\n",
        "Hiểu cách các mô hình học sâu hoạt động\n",
        "\n",
        "Triển khai các model tiên tiến nhất với Pytorch bao gồm thị giác máy tính và xử lý ngôn ngữ tự nhiên\n",
        "\n",
        "Cách làm việc với nhiều loại dữ liệu khác nhau để xây dựng model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLh5_uDypJK-",
        "outputId": "fc7a2bfb-a1b5-4975-f10e-0932d0c42d9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_test_path = 'test.txt'\n",
        "test_counter = count_tokens_in_file(file_test_path, min_length)\n",
        "testVocab = vocab(test_counter, specials=[unk_token, pad_token , bos_token, eos_token])\n",
        "test_data = data_process(file_test_path, testVocab, 10, 30)"
      ],
      "metadata": {
        "id": "ZRm1AFMvpSqD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQLNO9tGrb9L",
        "outputId": "f25740f4-f665-48ee-84a5-e8734b7b1983"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Những': 1,\n",
              "         'gì': 1,\n",
              "         'bạn': 1,\n",
              "         'sẽ': 1,\n",
              "         'học': 1,\n",
              "         'được': 1,\n",
              "         'từ': 1,\n",
              "         'lớp học': 1,\n",
              "         'này': 1,\n",
              "         '\\n': 7,\n",
              "         'Hiểu': 1,\n",
              "         'cách': 1,\n",
              "         'các': 2,\n",
              "         'mô hình học': 1,\n",
              "         'sâu': 1,\n",
              "         'hoạt động': 1,\n",
              "         'Triển khai': 1,\n",
              "         'model': 2,\n",
              "         'tiên tiến': 1,\n",
              "         'nhất': 1,\n",
              "         'với': 2,\n",
              "         'Pytorch': 1,\n",
              "         'bao gồm': 1,\n",
              "         'thị giác': 1,\n",
              "         'máy tính': 1,\n",
              "         'và': 1,\n",
              "         'xử lý': 1,\n",
              "         'ngôn ngữ': 1,\n",
              "         'tự nhiên': 1,\n",
              "         'Cách': 1,\n",
              "         'làm việc': 1,\n",
              "         'nhiều': 1,\n",
              "         'loại': 1,\n",
              "         'dữ liệu': 1,\n",
              "         'khác': 1,\n",
              "         'nhau': 1,\n",
              "         'để': 1,\n",
              "         'xây dựng': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l873evBSq5ta",
        "outputId": "5362d195-2734-4640-f7a2-a387b7c79280"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13]),\n",
              " tensor([20, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 13]),\n",
              " tensor([33, 34, 24, 35, 36, 37, 38, 39, 40, 41, 21, 13])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kết quả mong đợi\n",
        "\n",
        "```python\n",
        "\n",
        "[tensor([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13]),\n",
        " tensor([20, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 13]),\n",
        " tensor([33, 34, 24, 35, 36, 37, 38, 39, 40, 41, 21, 13])]\n",
        "```"
      ],
      "metadata": {
        "id": "P2HH4KF5sUmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 4\n",
        "PAD_IDX = torchVocab['<pad>']\n",
        "BOS_IDX = torchVocab['<bos>']\n",
        "EOS_IDX = torchVocab['<eos>']"
      ],
      "metadata": {
        "id": "OsVE3qe2s_oy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EOS_IDX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r78P4uK1mlop",
        "outputId": "81e653fd-f055-4142-fbfe-ae6da1d09a1a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lập trình hàm chia batch\n",
        "\n",
        "Hàm `generate_batch` là một hàm được thiết kế để xử lý các batch dữ liệu (batch) và chuẩn bị chúng để có thể được sử dụng trong các mô hình học máy, đặc biệt là trong xử lý ngôn ngữ tự nhiên. Dưới đây là mô tả chi tiết về các đối số và giá trị trả về của hàm này:\n",
        "\n",
        "**Đối số:**\n",
        "1. `data_batch`: Một batch dữ liệu, thường là một danh sách các tensor. Mỗi tensor trong `data_batch` đại diện cho một mẫu dữ liệu (ví dụ, một câu hoặc đoạn văn).\n",
        "\n",
        "**Chức năng của Hàm:**\n",
        "- Hàm lặp qua mỗi mẫu dữ liệu (`vi_item`) trong `data_batch`.\n",
        "- Đối với mỗi `vi_item`:\n",
        "  - Tạo một tensor `pads` chứa các giá trị padding (PAD_IDX) với kích thước sao cho tổng chiều dài của `vi_item` sau khi thêm các giá trị padding sẽ bằng `max_length`.\n",
        "  - Sử dụng hàm `torch.cat` để ghép `vi_item` với các giá trị BOS_IDX (đánh dấu bắt đầu của chuỗi), EOS_IDX (đánh dấu kết thúc của chuỗi), và tensor `pads` chứa các giá trị padding.\n",
        "  - Thêm `vi_item` đã được xử lý vào danh sách `vi_batch`.\n",
        "- Cuối cùng, sử dụng hàm `pad_sequence` để chuẩn hóa kích thước của tất cả các mẫu trong `vi_batch`, đảm bảo rằng tất cả chúng có chiều dài như nhau bằng cách thêm các giá trị padding (PAD_IDX) ở cuối nếu cần.\n",
        "\n",
        "**Giá trị trả về:**\n",
        "- Hàm trả về `vi_batch`, là một tensor đã được chuẩn hóa về kích thước, với mỗi mẫu dữ liệu trong batch đều có cùng chiều dài `max_length`.\n"
      ],
      "metadata": {
        "id": "UQJ3CNybOK5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(data_batch):\n",
        "  vi_batch = []\n",
        "\n",
        "  # TODO 7: Lập trình tại đây\n",
        "  for vi_item in data_batch:\n",
        "      pads = torch.full(size=(max_length - vi_item.shape[0],), fill_value=PAD_IDX, dtype=torch.long)\n",
        "      vi_item = torch.cat([torch.tensor([BOS_IDX]), vi_item, torch.tensor([EOS_IDX]), pads], dim=0)\n",
        "      vi_batch.append(vi_item)\n",
        "  vi_batch = pad_sequence(vi_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "  return vi_batch\n"
      ],
      "metadata": {
        "id": "tJ_UbVKxtAl3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code"
      ],
      "metadata": {
        "id": "IMLhBuR6O4tQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_generate_batch():\n",
        "    try:\n",
        "        # Test Case 1: Single item in data_batch\n",
        "        data_batch = [torch.tensor([3, 4, 5])]\n",
        "        batch = generate_batch(data_batch)\n",
        "        assert batch.shape == (1, 32), \"Failed: Shape mismatch in single item test\"\n",
        "\n",
        "        # Test Case 2: Multiple items in data_batch of different lengths\n",
        "        data_batch = [torch.tensor([3, 4, 5]), torch.tensor([6, 7])]\n",
        "        batch = generate_batch(data_batch)\n",
        "        assert batch.shape == (2, 32), \"Failed: Shape mismatch in multiple items test\"\n",
        "\n",
        "        # Test Case 3: Check if BOS_IDX and EOS_IDX are added correctly\n",
        "        data_batch = [torch.tensor([3])]\n",
        "        batch = generate_batch(data_batch)\n",
        "        assert batch[0][0] == BOS_IDX and batch[0][2] == EOS_IDX, \"Failed: BOS_IDX or EOS_IDX missing\"\n",
        "\n",
        "        print(\"All tests passed.\")\n",
        "    except AssertionError as e:\n",
        "        print(e)\n",
        "\n",
        "# Run the tests\n",
        "test_generate_batch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bepj_0MNPrtD",
        "outputId": "f859b21c-d080-4012-f946-f7713dfa9391"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All tests passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kết quả mong đợi:**\n",
        "\n",
        "All tests passed.\n"
      ],
      "metadata": {
        "id": "J3cGc4c-QS2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "test_iter = DataLoader(test_data, batch_size=4,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "for item in test_iter:\n",
        "    print('Chiều: ', item.shape)\n",
        "    print('Giá trị')\n",
        "    print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvZIMo-stSRw",
        "outputId": "6aedc74b-8ebb-46e9-ed42-91849b81dc2f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chiều:  torch.Size([3, 32])\n",
            "Giá trị\n",
            "tensor([[ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  3,  1,  1,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 33, 34, 24, 35, 36, 37, 38, 39, 40, 41, 21, 13,  3,  1,  1,  1,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
            "        [ 2, 20, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 13,  3,  1,\n",
            "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kết quả mong đợi:**\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Chiều:  torch.Size([3, 32])\n",
        "Giá trị\n",
        "tensor([[ 2, 33, 34, 24, 35, 36, 37, 38, 39, 40, 41, 21, 13,  3,  1,  1,  1,  1,\n",
        "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
        "        [ 2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13,  3,  1,  1,  1,  1,  1,  1,\n",
        "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
        "        [ 2, 20, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 13,  3,  1,\n",
        "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XVFY1L3Tto8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thực hiện build trên bộ wiki lớn"
      ],
      "metadata": {
        "id": "M99m1nfotuGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "train_iter = DataLoader(train_data, batch_size=8,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "\n",
        "# for item in train_iter:\n",
        "#     print('Chiều: ', item.shape)\n",
        "#     print('Giá trị')\n",
        "#     print(item)"
      ],
      "metadata": {
        "id": "BCeQyKbAtv9R"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save vocab"
      ],
      "metadata": {
        "id": "wKx4L2i9t0DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(torchVocab, 'wikiVocab.pth')"
      ],
      "metadata": {
        "id": "_7tJ3IV8tzxM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load vocab"
      ],
      "metadata": {
        "id": "73vvZufNt8vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torchVocab = torch.load('wikiVocab.pth')"
      ],
      "metadata": {
        "id": "Hdxk7jEJt9s-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torchVocab[\"tiên tiến\"]"
      ],
      "metadata": {
        "id": "PT_QgkWNiAkk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Phần 2: Xây dựng mô hình GPT Decoder\n",
        "---\n",
        "![](https://storage.googleapis.com/protonx-cdn/Screen%20Shot%202024-01-29%20at%2015.26.02.png)\n",
        "\n",
        "Để hiểu được mô hình, xem chi tiết video buổi hướng dẫn phần 2 ở trong lớp học\n"
      ],
      "metadata": {
        "id": "tKZpngqjUE-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kiến trúc lớp Decoder**\n",
        "- Lớp MultiheadAttention\n",
        "- Sau đó đi qua các lớp Layer Norm và Dropout"
      ],
      "metadata": {
        "id": "IklKJtdhokxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class GPTDecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1):\n",
        "        super(GPTDecoderLayer, self).__init__()\n",
        "        # TODO 1: Tạo cơ chế Multihead Attention với chiều embedding là d_model, số head là nhead và tỷ lệ dropout đã chỉ định\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # TODO 2: Tạo phép biến đổi tuyến tính đầu tiên\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        # TODO 3: Thêm dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        # TODO 4: Tạo phép biến đổi tuyến tính thứ hai\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        # TODO 5: Tạo phép LayerNorm 1\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # TODO 6: Tạo phép LayerNorm 2\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        # TODO 7: Tạo phép Dropout 1\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # TODO 8: Tạo phép Dropout 2\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        # TODO 9: Tạo phép activation ReLU\n",
        "        self.activation = F.relu\n",
        "\n",
        "    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n",
        "\n",
        "        # TODO 10: Áp dụng cơ chế Multihead Attention\n",
        "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # TODO 11: Áp dụng Dropout 1 và thêm kết quả vào đầu vào\n",
        "        src = src + self.dropout1(src2)\n",
        "\n",
        "        # TODO 12: Áp dụng LayerNorm 1\n",
        "        src = self.norm1(src)\n",
        "\n",
        "        # TODO 13: Áp dụng phép biến đổi tuyến tính - chú ý thêm activation\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "\n",
        "        # TODO 14: Áp dụng Dropout 2 và thêm kết quả vào đầu vào\n",
        "        src = src + self.dropout2(src2)\n",
        "\n",
        "        # TODO 15: Áp dụng LayerNorm 2\n",
        "        src = self.norm2(src)\n",
        "        return src\n"
      ],
      "metadata": {
        "id": "26jNFVT4Z8lJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Code"
      ],
      "metadata": {
        "id": "s0ZuoHQXbk_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_initialization():\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    dim_feedforward = 2048\n",
        "    dropout = 0.1\n",
        "    decoder_layer = GPTDecoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
        "    assert isinstance(decoder_layer.self_attn, nn.MultiheadAttention), \"self_attn is not an instance of MultiheadAttention\"\n",
        "    print('Passed')\n",
        "\n",
        "def test_multihead_attention():\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    sample_input = torch.rand(10, 32, d_model)\n",
        "    multihead_attn = nn.MultiheadAttention(d_model, nhead)\n",
        "\n",
        "    attn_output, _ = multihead_attn(sample_input, sample_input, sample_input)\n",
        "    assert attn_output.shape == sample_input.shape, \"Output shape of multihead attention is incorrect\"\n",
        "    print('Passed')\n",
        "\n",
        "\n",
        "\n",
        "def test_forward():\n",
        "    d_model = 512\n",
        "    nhead = 8\n",
        "    dim_feedforward = 2048\n",
        "    dropout = 0.1\n",
        "    decoder_layer = GPTDecoderLayer(d_model, nhead, dim_feedforward, dropout)\n",
        "    sample_input = torch.rand(10, 32, d_model)\n",
        "\n",
        "    output = decoder_layer(sample_input)\n",
        "    assert output.shape == sample_input.shape, \"Output shape in forward pass is incorrect\"\n",
        "    print('Passed')\n",
        "\n",
        "# Run tests\n",
        "test_initialization()\n",
        "test_multihead_attention()\n",
        "test_forward()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skxA5cTXbcea",
        "outputId": "5a98bba7-e818-4aa5-a9e1-05a7bdd45214"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passed\n",
            "Passed\n",
            "Passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kết quả mong đợi:\n",
        "\n",
        "```python\n",
        "Passed\n",
        "Passed\n",
        "Passed\n",
        "```"
      ],
      "metadata": {
        "id": "1FnTVe-Fbq1D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kiến trúc mô hình GPT**\n",
        "- Embedding của các token trong câu\n",
        "- Embedding để học vị trí của các từ trong câu - Gọi là Positional Embedding\n",
        "- Chuỗi các layer Decoder\n",
        " - Multihead Attention\n",
        " - Hàm chuẩn hóa Norm và Add\n",
        "- Lớp Linear cuối cùng"
      ],
      "metadata": {
        "id": "i6AKLiitVRvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, num_layers, d_model, nhead, vocab_size, max_seq_length, dim_feedforward=2048, dropout=0.1):\n",
        "        super(GPTModel, self).__init__()\n",
        "\n",
        "        # TODO 16: Tạo embedding cho các token đầu vào.\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # TODO 17: Tạo embedding cho mã hóa vị trí\n",
        "        self.pos_embedding = nn.Embedding(max_seq_length, d_model)\n",
        "\n",
        "        # TODO 18: Khởi tạo một danh sách các đối tượng GPTDecoderLayer, tạo nên cốt lõi của mô hình GPT. Dùng hàm ModuleList\n",
        "        self.layers = nn.ModuleList([GPTDecoderLayer(d_model, nhead, dim_feedforward, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        # TODO 19: Lớp tuyến tính cuối cùng để tìm ra từ tiếp theo\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_length = x.size(1)\n",
        "\n",
        "        # TODO 20: Tạo một mảng các vị trí từ 0 đến seq_length - 1\n",
        "        positions = torch.arange(seq_length, device=x.device, dtype=torch.long)\n",
        "\n",
        "        # TODO 21: Áp dụng embedding vị trí\n",
        "        positions = self.pos_embedding(positions)\n",
        "\n",
        "        # TODO 22: Nhân embedding của chuỗi token với căn bậc 2 của d_model\n",
        "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
        "\n",
        "        # TODO 23: Cộng embedding của chuỗi token với embedding của vị trí\n",
        "        x += positions\n",
        "\n",
        "        # TODO 24: Đưa chuỗi kết quả qua các lớp Decoder\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # TODO 25: Đưa qua lớp Linear cuối cùng\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "C_D2Z5CBafIy"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_initialization_with_valid_parameters():\n",
        "    try:\n",
        "        model = GPTModel(num_layers=2, d_model=512, nhead=8, vocab_size=10000, max_seq_length=50)\n",
        "        print(\"Test passed: Initialization with valid parameters.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "\n",
        "def test_forward_pass_with_valid_input():\n",
        "    try:\n",
        "        model = GPTModel(num_layers=2, d_model=512, nhead=8, vocab_size=10000, max_seq_length=50)\n",
        "        input_tensor = torch.randint(0, 10000, (1, 50))\n",
        "        output = model(input_tensor)\n",
        "        print(\"Test passed: Forward pass with valid input.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "\n",
        "def test_forward_pass_with_invalid_input_size():\n",
        "    try:\n",
        "        model = GPTModel(num_layers=2, d_model=512, nhead=8, vocab_size=10000, max_seq_length=50)\n",
        "        input_tensor = torch.randint(0, 10000, (1, 51))  # Invalid size\n",
        "        output = model(input_tensor)\n",
        "        print(\"Test failed: Invalid input size should have caused an error.\")\n",
        "    except Exception as e:\n",
        "        print(\"Test passed: Caught an error with invalid input size.\")\n",
        "\n",
        "\n",
        "def test_output_shape():\n",
        "    try:\n",
        "        model = GPTModel(num_layers=2, d_model=512, nhead=8, vocab_size=10000, max_seq_length=50)\n",
        "        input_tensor = torch.randint(0, 10000, (1, 50))\n",
        "        output = model(input_tensor)\n",
        "        assert output.shape == (1, 50, 10000), \"Output shape is incorrect.\"\n",
        "        print(\"Test passed: Output shape is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "\n",
        "def test_layer_counts():\n",
        "    try:\n",
        "        num_layers = 2\n",
        "        model = GPTModel(num_layers=num_layers, d_model=512, nhead=8, vocab_size=10000, max_seq_length=50)\n",
        "        assert len(model.layers) == num_layers, \"Incorrect number of layers.\"\n",
        "        print(\"Test passed: Layer count is correct.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Test failed: {e}\")\n",
        "\n",
        "\n",
        "test_initialization_with_valid_parameters()\n",
        "test_forward_pass_with_valid_input()\n",
        "test_forward_pass_with_invalid_input_size()\n",
        "test_output_shape()\n",
        "test_layer_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QwYpwPxc1a9",
        "outputId": "ac308938-b929-4dd7-d9db-52ed8f5a6b94"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed: Initialization with valid parameters.\n",
            "Test passed: Forward pass with valid input.\n",
            "Test passed: Caught an error with invalid input size.\n",
            "Test passed: Output shape is correct.\n",
            "Test passed: Layer count is correct.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kết quả mong đợi\n",
        "\n",
        "```python\n",
        "Test passed: Initialization with valid parameters.\n",
        "Test passed: Forward pass with valid input.\n",
        "Test passed: Caught an error with invalid input size.\n",
        "Test passed: Output shape is correct.\n",
        "Test passed: Layer count is correct.\n",
        "```"
      ],
      "metadata": {
        "id": "crgZbc7nePZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Khởi tạo mô hình"
      ],
      "metadata": {
        "id": "Or1wHmbleVAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 6\n",
        "d_model = 512\n",
        "nhead = 8\n",
        "vocab_size = len(torchVocab)\n",
        "max_seq_length = 32\n",
        "\n",
        "# Tạo mô hình\n",
        "model = GPTModel(num_layers, d_model, nhead, vocab_size, max_seq_length)\n",
        "\n",
        "# Tạo mẫu đơn giản với chiều (batch_size, max_seq_length): (1, 32)\n",
        "example_input = torch.randint(0, vocab_size, (1, 32))\n",
        "output = model(example_input)\n",
        "\n",
        "print(output.shape)  # Đầu ra [1, 32, vocab_size]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ju3fA8naim8",
        "outputId": "9242153a-0c80-41a5-e69a-8f19a6222eff"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 42])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hàm đánh giá\n",
        "def evaluate(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            batch = batch.to(device)\n",
        "            inputs, labels = batch[:, :-1], batch[:, 1:]\n",
        "            outputs_reshaped = outputs.reshape(-1, outputs.size(-1))\n",
        "            labels_reshaped = labels.reshape(-1)\n",
        "            loss = criterion(outputs_reshaped, labels_reshaped)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "zdmWOPbRRx_r"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Di chuyển model đến GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Tiến hành training\n",
        "num_epochs = 20  # Số epochs\n",
        "model.train()  # Chuyển chế độ thành train\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_iter:\n",
        "        # Chuyển data sang device\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        # Sắp xếp data để training\n",
        "        inputs, labels = batch[:, :-1], batch[:, 1:]\n",
        "\n",
        "        # Chiều xuôi\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        outputs_reshaped = outputs.reshape(-1, outputs.size(-1))\n",
        "        labels_reshaped = labels.reshape(-1)\n",
        "        loss = criterion(outputs_reshaped, labels_reshaped)\n",
        "\n",
        "        # Chiều ngược và cập nhật tham số\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    avg_loss = total_loss / len(train_iter)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(\"Training completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QESpHY1mafJj",
        "outputId": "86ddb72c-64bf-4748-fba8-c16b5ce28d6d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 4.0686\n",
            "Epoch [2/20], Loss: 3.7656\n",
            "Epoch [3/20], Loss: 5.2404\n",
            "Epoch [4/20], Loss: 1.7367\n",
            "Epoch [5/20], Loss: 1.2405\n",
            "Epoch [6/20], Loss: 1.0030\n",
            "Epoch [7/20], Loss: 1.0999\n",
            "Epoch [8/20], Loss: 1.0888\n",
            "Epoch [9/20], Loss: 0.8094\n",
            "Epoch [10/20], Loss: 0.5838\n",
            "Epoch [11/20], Loss: 0.3621\n",
            "Epoch [12/20], Loss: 0.2917\n",
            "Epoch [13/20], Loss: 0.1923\n",
            "Epoch [14/20], Loss: 0.1530\n",
            "Epoch [15/20], Loss: 0.1360\n",
            "Epoch [16/20], Loss: 0.1147\n",
            "Epoch [17/20], Loss: 0.1003\n",
            "Epoch [18/20], Loss: 0.0695\n",
            "Epoch [19/20], Loss: 0.0784\n",
            "Epoch [20/20], Loss: 0.0641\n",
            "Training completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kết quả mong đợi (Tương đối)**\n",
        "\n",
        "```python\n",
        "Epoch [1/20], Loss: 3.7509\n",
        "Epoch [2/20], Loss: 3.8950\n",
        "Epoch [3/20], Loss: 5.0087\n",
        "Epoch [4/20], Loss: 1.6143\n",
        "Epoch [5/20], Loss: 0.9752\n",
        "Epoch [6/20], Loss: 0.7447\n",
        "Epoch [7/20], Loss: 0.6585\n",
        "Epoch [8/20], Loss: 0.5026\n",
        "Epoch [9/20], Loss: 0.5309\n",
        "Epoch [10/20], Loss: 0.4016\n",
        "Epoch [11/20], Loss: 0.3491\n",
        "Epoch [12/20], Loss: 0.2637\n",
        "Epoch [13/20], Loss: 0.2202\n",
        "Epoch [14/20], Loss: 0.1943\n",
        "Epoch [15/20], Loss: 0.1399\n",
        "Epoch [16/20], Loss: 0.1155\n",
        "Epoch [17/20], Loss: 0.0927\n",
        "Epoch [18/20], Loss: 0.0733\n",
        "Epoch [19/20], Loss: 0.0730\n",
        "Epoch [20/20], Loss: 0.0586\n",
        "Training completed\n",
        "```"
      ],
      "metadata": {
        "id": "AoaUNaShsGdZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thử decode"
      ],
      "metadata": {
        "id": "rt8RClTXsB1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('Những')\n",
        "vi_tensor_ = torch.tensor([torchVocab[str(token)] for token in doc], dtype=torch.long)\n",
        "vi_item = torch.cat([torch.tensor([BOS_IDX]), vi_tensor_], dim=0)\n",
        "input_ids = torch.tensor(vi_item, dtype=torch.long).unsqueeze(0)\n",
        "input_ids = input_ids.to(device)\n",
        "\n",
        "for _ in range(max_length):\n",
        "    outputs = model(input_ids)\n",
        "    predictions = outputs[:, -1, :].argmax(dim=-1)\n",
        "    pred_item = predictions.unsqueeze(-1)\n",
        "    input_ids = torch.cat([input_ids, pred_item], dim=-1)\n",
        "    if pred_item == EOS_IDX:\n",
        "        break\n",
        "    print(torchVocab.lookup_token(pred_item))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8yFLOCgdf0g",
        "outputId": "10b60388-053f-4184-f7a2-094098a9d44a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-8e44b1ae2302>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_ids = torch.tensor(vi_item, dtype=torch.long).unsqueeze(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gì\n",
            "bạn\n",
            "sẽ\n",
            "học\n",
            "được\n",
            "từ\n",
            "lớp học\n",
            "này\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-cKwJuu_nL2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}